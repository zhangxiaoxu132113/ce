package com.water.crawl.core.category;

import java.io.IOException;

import jeasy.analysis.MMAnalyzer;

public class ChineseSpliter {
	/**
	 * 对给定的文本进行中文分词
	 * 
	 * @param text
	 *            给定的文本
	 * @param splitToken
	 *            用于分割的标记,如"|"
	 * @return 分词完毕的文本
	 */
	public static String split(String text, String splitToken) {
		String result = null;
		MMAnalyzer analyzer = new MMAnalyzer();
		try {
			result = analyzer.segment(text, splitToken);
		} catch (IOException e) {
			e.printStackTrace();
		}
		return result;
	}
	public static void main(String[] args) {
		long start = System.currentTimeMillis();
		String test = "本文为第一部分,着重介绍文本预处理以及特征抽取的方法"
				+ "随着互联网技术的迅速发展与普及，如何对浩如烟海的数据进行分类、组织和管理，已经成为一个具有重要用途的研究课题。而在这些数据中，文本数据又是数量最大的一类。“文本分类是指在给定分类体系下，根据文本内容自动确定文本类别的过程”（达观数据科技联合创始人，张健）。文本分类有着广泛的应用场景，例如："
				+ "新闻网站包含大量报道文章，基于文章内容，需要将这些文章按题材进行自动分类（例如自动划分成政治、经济、军事、体育、娱乐等。"
				+ "在电子商务网站，用户进行了交易行为后对商品进行评价分类，商家需要对用户的评价划分为正面评价和负面评价，来获取各个商品的用户反馈统计情况。"
				+ "电子邮箱频繁接收到垃圾广告信息，通过文本分类技术从众多的邮件中识别垃圾邮件并过滤，提高了邮箱用户的使用效率。"
				+ "媒体每日有大量投稿，依靠文本分类技术能够对文章进行自动审核，标记投稿中的色情、暴力、政治、垃圾广告等违规内容。"
				+ "20世纪90年代以前，占主导地位的文本分类方法一直是基于知识工程的方法：借助专业人员的帮助，为每个类别定义大量的推理规则，如果一篇文档能满足这些推理规则，则可以判定属于该类别。但是这种方法有明显的缺点：分类的质量依赖于规则的好坏；需要大量的专业人员进行规则的制定；不具备可推广性，不同的领域需要构建完全不同的分类系统，造成开发资源和资金资源的巨大浪费。"
				+ "而机器学习技术能很好地解决上述问题，以统计理论为基础，利用算法让机器具有类似人类般的自动“学习”能力——对已知的训练数据做统计分析从而获得规律，再运用规律对未知数据做预测分析。机器学习方法运用在文本分类上的基本过程就是：标注——利用人工对一批文档进行了准确分类，以作为训练集（进行机器学习的材料）；训练——计算机从这些文档中挖掘出一些能够有效分类的规则，生成分类器（总结出的规则集合）；分类——将生成的分类器应用在有待分类的文档集合中，获取文档的分类结果。由于机器学习方法在文本分类领域有着良好的实际表现，已经成为了该领域的主流。"
				+ "达观数据团队在处理海量数据方面具有丰富的经验，在文本分类技术方面有深入的实践，并将文本分类技术成功运用到了线上服务中，取得了良好的效果。本文整理了文本分类的基本方法和处理流程，进行了综述性介绍。"
				+ "（一）：文本预处理1.文本分类流程文本分类的流程如图 1所示，包括训练、特征抽取、训练模型、分类预测等几个主要环节。"
				+ "图 1 文本分类流程图2.文本预处理2.1文档建模"
				+ "机器学习方法让计算机自己去学习已经分类好的训练集，然而计算机是很难按人类理解文章那样来学习文章，因此，要使计算机能够高效地处理真实文本，就必须找到一种理想的形式化表示方法，这个过程就是文档建模。文档建模一方面要能够真实地反映文档的内容，另一方面又要对不同文档具有区分能力。文档建模比较通用的方法包括布尔模型、向量空间模型（VSM）和概率模型。其中最为广泛使用的是向量空间模型。"
				+ "经典的向量空间模型(VSM： Vector Space Model)由Salton等人于60年代提出，并成功地应用于著名的SMART文本检索系统。VSM概念非常直观——把对文本内容的处理简化为向量空间中的向量运算，并且它以空间上的相似度表达语义的相似度，直观易懂。当文档被表示为文档空间的向量时，就可以通过计算向量之间的相似性来度量文档间的相似性。文本处理中最常用的相似性度量方式是余弦距离。文本挖掘系统采用向量空间模型，用特征词条(T1，T2，…Tn)及其权值Wi代表目标信息，在进行信息匹配时，使用这些特征项评价未知文本与目标样本的相关程度。特征词条及其权值的选取称为目标样本的特征提取，特征提取算法的优劣将直接影响到系统的运行效果。"
				+ "设D为一个包含m个文档的文档集合Di为第i个文档的特征向量，则有D={D1，D2，…，Dm}， Di=(di1di2…dij)，i=12，…，m j=1，2，…，n。其中dij(i=1，2，…，m； j=1，2，…，n)为文档Di中第j个词条tj的权值它一般被定义为tj在Di中出现的频率tij的函数，例如采用TF-IDF函数，即dij=tij*log(N/nj)。其中N是文档数据库中文档总数，nj是文档数据库含有词条tj的文档数目。假设用户给定的文档向量为D2，未知的文档向量为q，两者的相似程度可用两向量的夹角余弦来度量，夹角越小说明相似度越高。相似度的计算公式如下"
				+ "图 2 向量空间模型"
				+ "通过上述的向量空间模型，文本数据就转换成了计算机可以处理的结构化数据，两个文档之间的相似性问题转变成了两个向量之间的相似性问题。"
				+ "2.2 中文分词技术"
				+ "在使用向量模型表示文档时，首先要对文档进行词汇化处理。对于英语或者法语等语言来说，将文档转化成词的集合比较简单，但是对于汉语来说，不像英文文本的单词那样有空格来区分，这个处理过程要依赖于分词技术。从简单的查词典的方法，到"
				+ "后来的基于统计语言模型的分词方法，中文分词的技术已趋于成熟。但是，尽管现在分词软件的准确率已经比较高了，它对专业术语（称为未登录词识别）"
				+ "的识别率还不是很好。例如“来自星星的你”，分词可以成功切分为“来自\\星星\\的\\你”，但是怎样把“来自星星的你”作为一个完整的专有名词（电视剧名称）识别出来，还有很多技术要解决。为了进一步提高关键词抽取的准确率，通常需要在词库中添加专名词表来保证分词的质量。"
				+ "在完成分词之后，我们对词语的位置信息做进一步的发掘，需要确定记录位置信息的方式以及各个位置的词在反映主题时的相对重要性。标题、摘要和结论、正文等文章各个部分的位置权重是各不相同的，当软件逐词扫描统计词频时，记录每个词的位置信息。"
				+ "在计算文档的特征向量的值时，还需要对文本集进行一些处理，过滤掉无用的信息。滤除这些没有作用的词语可以减少文本特征向量的维数，减少不必要的运算。常见做法包括：";
		for(String str : split(test," ").split(" ")) {
			System.out.println(str);
		}
		long end = System.currentTimeMillis();
		System.out.println(end - start);
	}
}
